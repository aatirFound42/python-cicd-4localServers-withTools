name: Python CI/CD Pipeline - Enhanced

on:
  push:
    branches: [ "main", "develop" ]
    tags: [ 'v*.*.*' ]
  pull_request:
    branches: [ "main", "develop" ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  PYTHON_VERSION: '3.9'
  CACHE_VERSION: v1  # Increment to bust cache

jobs:
  
  # ====== STAGE 1: BUILD ======
  build:
    name: Build Docker Image
    if: "!contains(github.event.head_commit.message, '[deploy-only]')"
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: read
      packages: write
    
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build-push.outputs.digest }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to GitHub Container Registry
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set lowercase image name
        run: |
          echo "IMAGE_NAME=$(echo ${{ env.IMAGE_NAME }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
          
      - name: Extract Docker metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
      
      - name: Build and push Docker image
        id: build-push
        uses: docker/build-push-action@v5
        with:
          context: .
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1

      - name: Display build summary
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… Docker Image Built Successfully"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“¦ Image Tags:"
          echo "${{ steps.meta.outputs.tags }}" | sed 's/^/   /'
          echo ""
          echo "ğŸ”‘ Image Digest: ${{ steps.build-push.outputs.digest }}"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # ====== STAGE 2: CONTAINER SECURITY SCAN ======
  scan-image:
    name: Scan Docker Image
    if: "!contains(github.event.head_commit.message, '[deploy-only]')"
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: build
    permissions:
      contents: read
      packages: read
      security-events: write
    
    steps:
      - name: Set lowercase image name
        run: |
          echo "IMAGE_NAME=$(echo ${{ env.IMAGE_NAME }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
      
      - name: Log in to GitHub Container Registry
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Determine image tag
        id: image-tag
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            TAG="pr-${{ github.event.pull_request.number }}"
          else
            TAG="${{ github.ref_name }}"
          fi
          echo "tag=$TAG" >> $GITHUB_OUTPUT
          echo "Using image tag: $TAG"
      
      - name: Pull Docker image
        run: |
          IMAGE="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.image-tag.outputs.tag }}"
          echo "Pulling image: $IMAGE"
          
          if docker pull "$IMAGE" 2>&1; then
            echo "âœ… Image pulled successfully"
          else
            echo "âš ï¸ Image not available, will skip scanning"
            echo "SKIP_SCAN=true" >> $GITHUB_ENV
            exit 0
          fi
      
      - name: Run Trivy vulnerability scanner
        if: env.SKIP_SCAN != 'true'
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: '${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.image-tag.outputs.tag }}'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
        continue-on-error: true
      
      - name: Run Trivy JSON report
        if: env.SKIP_SCAN != 'true'
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ³ Scanning Docker Image for Vulnerabilities"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Install Trivy using modern GPG method
          wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | \
            sudo gpg --dearmor -o /usr/share/keyrings/trivy.gpg
          
          echo "deb [signed-by=/usr/share/keyrings/trivy.gpg] https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | \
            sudo tee /etc/apt/sources.list.d/trivy.list
          
          sudo apt-get update
          sudo apt-get install trivy -y
          
          IMAGE="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.image-tag.outputs.tag }}"
          
          # Run scan and generate JSON report
          trivy image --format json --output trivy-report.json "$IMAGE" || true
          
          if [ -f trivy-report.json ]; then
            CRITICAL=$(python3 << 'PYTHON_EOF'
          import json
          try:
              with open('trivy-report.json') as f:
                  data = json.load(f)
                  count = 0
                  for result in data.get('Results', []):
                      for vuln in result.get('Vulnerabilities', []):
                          if vuln.get('Severity') == 'CRITICAL':
                              count += 1
                  print(count)
          except:
              print(0)
          PYTHON_EOF
          )
            
            HIGH=$(python3 << 'PYTHON_EOF'
          import json
          try:
              with open('trivy-report.json') as f:
                  data = json.load(f)
                  count = 0
                  for result in data.get('Results', []):
                      for vuln in result.get('Vulnerabilities', []):
                          if vuln.get('Severity') == 'HIGH':
                              count += 1
                  print(count)
          except:
              print(0)
          PYTHON_EOF
          )
            
            echo "Results:"
            echo "  ğŸ”´ Critical: $CRITICAL"
            echo "  ğŸŸ  High:     $HIGH"
            
            if [ "$CRITICAL" -gt 0 ] || [ "$HIGH" -gt 0 ]; then
              echo ""
              echo "âš ï¸  Vulnerabilities detected in container image"
              echo "::warning::Trivy detected $CRITICAL critical and $HIGH high severity vulnerabilities"
              
              echo ""
              echo "Top vulnerabilities:"
              trivy image --format table --severity CRITICAL,HIGH "$IMAGE" | head -n 20
            else
              echo ""
              echo "âœ… No critical or high severity vulnerabilities found"
            fi
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        continue-on-error: true
      
      - name: Upload Trivy scan results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always() && env.SKIP_SCAN != 'true'
        with:
          sarif_file: 'trivy-results.sarif'
        continue-on-error: true
      
      - name: Upload Trivy reports
        if: always() && env.SKIP_SCAN != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: trivy-reports
          path: |
            trivy-results.sarif
            trivy-report.json


  # ====== STAGE 3: LINT ======
  lint:
    name: Code Quality & Linting
    if: "!contains(github.event.head_commit.message, '[deploy-only]')"
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: build
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      # âœ… IMPROVEMENT: Dependency caching
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lint-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-lint-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pip-lint-
      
      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install black isort flake8 pylint mypy pip-audit
      
      - name: Check code formatting with Black
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ¨ Checking Code Formatting (Black)"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          black --check app/ tests/ --line-length=100 --diff
          echo "âœ… Code formatting verified"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      
      - name: Check import sorting with isort
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“¦ Checking Import Order (isort)"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          isort --check-only --diff app/ tests/ --profile black
          echo "âœ… Import order verified"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      
      - name: Run Flake8 linting
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“‹ Running Flake8 Analysis"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          flake8 app/ tests/ --max-line-length=100 --statistics --show-source
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      
      - name: Run Pylint analysis
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“‹ Running Pylint Analysis"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          pylint app/ tests/ --fail-under=8.0 --output-format=colorized
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      
      - name: Run Mypy type checking
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ” Running Static Type Checking (Mypy)"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          mypy app/ --ignore-missing-imports --show-error-codes --pretty
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

      # âœ… IMPROVEMENT: Use pip-audit instead of deprecated safety
      - name: Run dependency security scan (pip-audit)
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ›¡ï¸  Scanning Dependencies for Vulnerabilities"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          if [ -f requirements.txt ]; then
            pip-audit --format json --output audit-report.json || true
            
            if [ -f audit-report.json ]; then
              VULN_COUNT=$(python3 << 'PYTHON_EOF'
                import json
                try:
                    with open('audit-report.json') as f:
                        data = json.load(f)
                        print(len(data.get('vulnerabilities', [])))
                except:
                    print(0)
                PYTHON_EOF
              )
              
              if [ "$VULN_COUNT" -gt 0 ]; then
                echo "âš ï¸  Found $VULN_COUNT vulnerable dependencies"
                echo ""
                pip-audit --format text || true
                echo ""
                echo "::warning::pip-audit detected $VULN_COUNT vulnerable dependencies"
              else
                echo "âœ… No vulnerable dependencies found"
              fi
            fi
          else
            echo "âš ï¸  requirements.txt not found"
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        continue-on-error: true
      
      - name: Upload dependency scan report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit-report
          path: audit-report.json

      - name: Scan for secrets in git history (TruffleHog)
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ” Scanning Git History for Secrets"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          pip install truffleHog3
          
          trufflehog3 --format json --output trufflehog-report.json . || true
          
          if [ -f trufflehog-report.json ]; then
            SECRET_COUNT=$(python3 << 'PYTHON_EOF'
              import json
              try:
                  with open('trufflehog-report.json') as f:
                      data = json.load(f)
                      if isinstance(data, list):
                          print(len(data))
                      else:
                          print(0)
              except:
                  print(0)
              PYTHON_EOF
            )
            
            if [ "$SECRET_COUNT" -gt 0 ]; then
              echo "âš ï¸  Found $SECRET_COUNT potential secrets in git history"
              echo "::warning::TruffleHog detected $SECRET_COUNT potential secrets"
            else
              echo "âœ… No secrets detected in git history"
            fi
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        continue-on-error: true
      
      - name: Upload git secrets report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trufflehog-report
          path: trufflehog-report.json
      
      - name: Linting summary
        if: always()
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… Code Quality Checks Completed"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ“ Black formatting"
          echo "âœ“ isort import order"
          echo "âœ“ Flake8 style guide"
          echo "âœ“ Pylint code quality"
          echo "âœ“ Mypy type checking"
          echo "âœ“ Dependency security scan"
          echo "âœ“ Secret detection"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"


  # ====== STAGE 4: TEST (MATRIX TESTING) ======
  test:
    name: Test (Python ${{ matrix.python-version }})
    if: "!contains(github.event.head_commit.message, '[deploy-only]')"
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [build, scan-image, lint]
    
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      # âœ… IMPROVEMENT: Better dependency caching
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-test-${{ matrix.python-version }}-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-test-${{ matrix.python-version }}-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pip-test-${{ matrix.python-version }}-
      
      # âœ… IMPROVEMENT: Install dependencies from multiple requirement files
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          
          # Install main dependencies
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            echo "âš ï¸  WARNING: requirements.txt not found"
            exit 1
          fi
          
          # Install dev dependencies if available
          if [ -f requirements-dev.txt ]; then
            pip install -r requirements-dev.txt
          fi
          
          # Install test dependencies
          pip install pytest-xdist pytest-timeout pytest-cov pytest-mock
          
          # Display installed packages
          echo ""
          echo "ğŸ“¦ Installed packages:"
          pip list

      - name: Run tests with coverage
        run: |
          if [ ! -d "tests/" ]; then
            echo "âŒ ERROR: tests/ directory not found"
            exit 1
          fi
          
          pytest tests/ \
            -v \
            --tb=short \
            --cov=app \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=json \
            --cov-report=term-missing \
            -n auto \
            --timeout=30 \
            --strict-markers

      - name: Check coverage threshold (85%)
        run: |
          if [ ! -f coverage.json ]; then
            echo "âŒ ERROR: coverage.json not found"
            exit 1
          fi
          
          python3 << 'PYTHON_EOF'
            import json
            import sys

            with open('coverage.json') as f:
                data = json.load(f)
                coverage = data['totals']['percent_covered']
                threshold = 85
                
                print('â”' * 60)
                print('Coverage Report')
                print('â”' * 60)
                print(f'Current:   {coverage:.2f}%')
                print(f'Required:  {threshold}%')
                print(f'Status:    ', end='')
                
                if coverage < threshold:
                    print('âŒ FAILED')
                    print('â”' * 60)
                    sys.exit(1)
                else:
                    print('âœ… PASSED')
                    print('â”' * 60)
                    sys.exit(0)
            PYTHON_EOF
          )
      
      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-html-${{ matrix.python-version }}
          path: htmlcov/
      
      - name: Upload coverage JSON
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-json-${{ matrix.python-version }}
          path: coverage.json
      
      - name: Security scan with Bandit
        run: |
          pip install bandit[toml]
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ”’ Running Bandit Security Scan"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          bandit -r app/ -f json -o bandit-report.json -ll || true
          
          if [ -f bandit-report.json ]; then
            ISSUE_COUNT=$(python3 -c "import json; data=json.load(open('bandit-report.json')); print(len(data.get('results', [])))" 2>/dev/null || echo "0")
            
            if [ "$ISSUE_COUNT" -gt 0 ]; then
              echo "âš ï¸  Found $ISSUE_COUNT security issue(s)"
              echo "::warning::Bandit detected $ISSUE_COUNT security issues"
            else
              echo "âœ… No security issues found"
            fi
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          fi
        continue-on-error: true
      
      - name: Secret scanning
        run: |
          pip install detect-secrets
          
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ” Running Secret Detection Scan"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          detect-secrets scan --all-files --force-use-all-plugins > .secrets.baseline || true
          
          if [ -f .secrets.baseline ]; then
            SECRET_COUNT=$(python3 -c "import json; data=json.load(open('.secrets.baseline')); print(len(data.get('results', {})))" 2>/dev/null || echo "0")
            
            if [ "$SECRET_COUNT" -gt 0 ]; then
              echo "âš ï¸  Found $SECRET_COUNT potential secret(s)"
            else
              echo "âœ… No secrets detected"
            fi
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          fi
        continue-on-error: true
      
      - name: Upload security reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-${{ matrix.python-version }}
          path: |
            bandit-report.json
            .secrets.baseline
      
      - name: Test summary
        if: always()
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… Test Suite Completed (Python ${{ matrix.python-version }})"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ“ Unit Tests"
          echo "âœ“ Integration Tests"
          echo "âœ“ Code Coverage (â‰¥85%)"
          echo "âœ“ Security Scans"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"


  # ====== STAGE 5: PERFORMANCE TESTING ======
  performance-test:
    name: Performance & Load Testing
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [build, test]
    if: "!contains(github.event.head_commit.message, '[deploy-only]')"
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Set lowercase image name
        run: |
          echo "IMAGE_NAME=$(echo ${{ env.IMAGE_NAME }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
      
      - name: Set performance test variables
        run: |
          # âœ… IMPROVEMENT: Use unique names to avoid conflicts
          echo "PERF_CONTAINER=perf-test-${{ github.run_id }}" >> $GITHUB_ENV
          echo "PERF_PORT=$((8080 + (${{ github.run_id }} % 1000)))" >> $GITHUB_ENV
      
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Start test container
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸš€ Starting Test Container for Performance Testing"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          IMAGE="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
          
          docker pull "$IMAGE"
          
          docker run -d \
            --name "$PERF_CONTAINER" \
            -p "$PERF_PORT:5000" \
            -e FLASK_ENV=testing \
            "$IMAGE"
          
          # Wait for container to be ready
          sleep 10
          
          # Health check
          for i in {1..5}; do
            if curl -sf "http://localhost:$PERF_PORT/api/health" >/dev/null 2>&1; then
              echo "âœ… Container is ready on port $PERF_PORT"
              break
            fi
            echo "â³ Waiting for container... ($i/5)"
            sleep 5
          done
      
      - name: Install performance testing tools
        run: |
          pip install locust pytest-benchmark
      
      - name: Run load tests with Locust
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Running Load Tests"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Create a basic locustfile if it doesn't exist
          if [ ! -f tests/performance/locustfile.py ]; then
            mkdir -p tests/performance
            cat > tests/performance/locustfile.py << 'LOCUST_EOF'
            from locust import HttpUser, task, between

            class APIUser(HttpUser):
                wait_time = between(1, 3)
                host = "http://localhost:$PERF_PORT"
                
                @task(3)
                def health_check(self):
                    """Health check endpoint - most frequent"""
                    self.client.get("/api/health")
                
                @task(2)
                def index(self):
                    """Index/root endpoint"""
                    self.client.get("/")
                
                @task(1)
                def api_endpoint(self):
                    """Sample API endpoint"""
                    self.client.get("/api/v1/data")
            LOCUST_EOF
          fi
          
          # Replace placeholder with actual port
          sed -i "s/\$PERF_PORT/$PERF_PORT/g" tests/performance/locustfile.py
          
          # Run locust headless
          locust -f tests/performance/locustfile.py \
            --headless \
            --users 50 \
            --spawn-rate 10 \
            --run-time 60s \
            --host "http://localhost:$PERF_PORT" \
            --html performance-report.html \
            --csv performance-results || true
          
          echo "âœ… Load tests completed"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      
      - name: Analyze performance results
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“ˆ Performance Test Results"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          if [ -f performance-results_stats.csv ]; then
            echo "Summary Statistics:"
            cat performance-results_stats.csv
            echo ""
            
            # Parse CSV and check metrics
            # CSV columns: Type,Name,Request Count,Failure Count,Median,Average,Min,Max,Content Size,Requests/s,Failures/s,50%,66%,75%,80%,90%,95%,98%,99%,99.9%,99.99%,100%
            
            # Get the aggregated row (last non-empty line)
            STATS_LINE=$(grep -v '^Type,Name' performance-results_stats.csv | tail -n 1)
            
            # Extract key metrics
            REQUEST_COUNT=$(echo "$STATS_LINE" | cut -d',' -f3 | tr -d ' ')
            FAILURE_COUNT=$(echo "$STATS_LINE" | cut -d',' -f4 | tr -d ' ')
            AVG_RESPONSE=$(echo "$STATS_LINE" | cut -d',' -f6 | tr -d ' ')
            P95_RESPONSE=$(echo "$STATS_LINE" | cut -d',' -f16 | tr -d ' ')
            RPS=$(echo "$STATS_LINE" | cut -d',' -f10 | tr -d ' ')
            
            # Calculate failure rate
            if [ "$REQUEST_COUNT" -gt 0 ]; then
              FAILURE_RATE=$(echo "scale=2; ($FAILURE_COUNT / $REQUEST_COUNT) * 100" | bc -l)
            else
              FAILURE_RATE="0"
            fi
            
            echo "ğŸ“Š Key Metrics:"
            echo "  Total Requests:    $REQUEST_COUNT"
            echo "  Failed Requests:   $FAILURE_COUNT"
            echo "  Failure Rate:      ${FAILURE_RATE}%"
            echo "  Requests/sec:      $RPS"
            echo "  Avg Response Time: ${AVG_RESPONSE}ms"
            echo "  P95 Response Time: ${P95_RESPONSE}ms"
            echo ""
            
            # Performance thresholds
            FAILURE_THRESHOLD=5.0
            AVG_RESPONSE_THRESHOLD=500
            P95_RESPONSE_THRESHOLD=1000
            
            PERF_FAILED=0
            
            # Check failure rate
            if [ $(echo "$FAILURE_RATE > $FAILURE_THRESHOLD" | bc -l) -eq 1 ]; then
              echo "âŒ FAILED: Failure rate ${FAILURE_RATE}% exceeds threshold ${FAILURE_THRESHOLD}%"
              PERF_FAILED=1
            else
              echo "âœ… PASSED: Failure rate within acceptable limits"
            fi
            
            # Check average response time
            if [ $(echo "$AVG_RESPONSE > $AVG_RESPONSE_THRESHOLD" | bc -l) -eq 1 ]; then
              echo "âš ï¸  WARNING: Average response time ${AVG_RESPONSE}ms exceeds ${AVG_RESPONSE_THRESHOLD}ms"
            else
              echo "âœ… PASSED: Average response time acceptable"
            fi
            
            # Check P95 response time
            if [ $(echo "$P95_RESPONSE > $P95_RESPONSE_THRESHOLD" | bc -l) -eq 1 ]; then
              echo "âš ï¸  WARNING: P95 response time ${P95_RESPONSE}ms exceeds ${P95_RESPONSE_THRESHOLD}ms"
            else
              echo "âœ… PASSED: P95 response time acceptable"
            fi
            
            echo ""
            
            # Add to GitHub summary
            echo "### ğŸ“Š Performance Test Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Value | Threshold | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|-----------|--------|" >> $GITHUB_STEP_SUMMARY
            echo "| Total Requests | $REQUEST_COUNT | - | â„¹ï¸ |" >> $GITHUB_STEP_SUMMARY
            echo "| Failure Rate | ${FAILURE_RATE}% | ${FAILURE_THRESHOLD}% | $([ $(echo "$FAILURE_RATE <= $FAILURE_THRESHOLD" | bc -l) -eq 1 ] && echo 'âœ…' || echo 'âŒ') |" >> $GITHUB_STEP_SUMMARY
            echo "| Requests/sec | $RPS | - | â„¹ï¸ |" >> $GITHUB_STEP_SUMMARY
            echo "| Avg Response | ${AVG_RESPONSE}ms | ${AVG_RESPONSE_THRESHOLD}ms | $([ $(echo "$AVG_RESPONSE <= $AVG_RESPONSE_THRESHOLD" | bc -l) -eq 1 ] && echo 'âœ…' || echo 'âš ï¸') |" >> $GITHUB_STEP_SUMMARY
            echo "| P95 Response | ${P95_RESPONSE}ms | ${P95_RESPONSE_THRESHOLD}ms | $([ $(echo "$P95_RESPONSE <= $P95_RESPONSE_THRESHOLD" | bc -l) -eq 1 ] && echo 'âœ…' || echo 'âš ï¸') |" >> $GITHUB_STEP_SUMMARY
            
            if [ $PERF_FAILED -eq 1 ]; then
              echo ""
              echo "âŒ Performance tests FAILED"
              exit 1
            fi
          else
            echo "âš ï¸  Performance results file not found"
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        continue-on-error: true
      
      - name: Run benchmark tests
        if: hashFiles('tests/benchmarks/*.py') != ''
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âš¡ Running Benchmark Tests"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          pytest tests/benchmarks/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --benchmark-columns=min,max,mean,median,stddev \
            --benchmark-sort=mean || true
          
          if [ -f benchmark-results.json ]; then
            echo ""
            echo "âœ… Benchmark tests completed"
            echo "Results saved to benchmark-results.json"
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        continue-on-error: true
      
      - name: Check container resource usage
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ’» Container Resource Usage"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Get container stats
          docker stats "$PERF_CONTAINER" --no-stream --format \
            "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.MemPerc}}\t{{.NetIO}}\t{{.BlockIO}}"
          
          # Extract memory percentage
          MEM_PERC=$(docker stats "$PERF_CONTAINER" --no-stream --format "{{.MemPerc}}" | sed 's/%//')
          
          echo ""
          if [ $(echo "$MEM_PERC < 80.0" | bc -l) -eq 1 ]; then
            echo "âœ… Memory usage: ${MEM_PERC}% (healthy)"
          else
            echo "âš ï¸  Memory usage: ${MEM_PERC}% (high)"
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        continue-on-error: true
      
      - name: Upload performance reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-reports
          path: |
            performance-report.html
            performance-results*.csv
            benchmark-results.json
      
      - name: Cleanup test container
        if: always()
        run: |
          echo "ğŸ§¹ Cleaning up test container..."
          docker stop "$PERF_CONTAINER" 2>/dev/null || true
          docker rm "$PERF_CONTAINER" 2>/dev/null || true
          echo "âœ… Cleanup completed"


  # ====== STAGE 6: QUALITY GATES ======
  quality-gates:
    name: Quality Gates
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [lint, test]
    if: "!contains(github.event.head_commit.message, '[deploy-only]')"
    
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Download coverage reports
        uses: actions/download-artifact@v4
        with:
          path: coverage-artifacts
      
      - name: Analyze coverage across Python versions
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Coverage Analysis Summary"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          for json_file in coverage-artifacts/coverage-json-*/coverage.json; do
            if [ -f "$json_file" ]; then
              version=$(basename $(dirname "$json_file") | sed 's/coverage-json-//')
              coverage=$(python3 -c "import json; f=open('$json_file'); d=json.load(f); print(f\"{d['totals']['percent_covered']:.2f}\")" 2>&1)
              
              if [ $? -eq 0 ]; then
                echo "Python $version: $coverage%"
              else
                echo "Python $version: âš ï¸  Failed to parse"
              fi
            fi
          done
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        
      - name: Security summary
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ”’ Security Scan Summary"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          echo "Bandit Results:"
          for scan_dir in coverage-artifacts/security-scan-*; do
            if [ -d "$scan_dir" ] && [ -f "$scan_dir/bandit-report.json" ]; then
              version=$(basename "$scan_dir" | sed 's/security-scan-//')
              issues=$(python3 -c "import json; f=open('$scan_dir/bandit-report.json'); d=json.load(f); print(len(d.get('results', [])))" 2>/dev/null || echo "0")
              
              if [ "$issues" -gt 0 ]; then
                echo "  Python $version: âš ï¸  $issues issue(s)"
              else
                echo "  Python $version: âœ… Clean"
              fi
            fi
          done
          
          echo ""
          echo "Secret Detection:"
          for scan_dir in coverage-artifacts/security-scan-*; do
            if [ -d "$scan_dir" ] && [ -f "$scan_dir/.secrets.baseline" ]; then
              version=$(basename "$scan_dir" | sed 's/security-scan-//')
              secrets=$(python3 -c "import json; f=open('$scan_dir/.secrets.baseline'); d=json.load(f); print(len(d.get('results', {})))" 2>/dev/null || echo "0")
              
              if [ "$secrets" -gt 0 ]; then
                echo "  Python $version: âš ï¸  $secrets potential secret(s)"
              else
                echo "  Python $version: âœ… Clean"
              fi
            fi
          done
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      
      - name: Comprehensive security summary
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ”’ Comprehensive Security Summary"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Dependency vulnerabilities
          if [ -f coverage-artifacts/pip-audit-report/audit-report.json ]; then
            DEPS=$(python3 << 'PYTHON_EOF'
              import json
              try:
                  with open('coverage-artifacts/pip-audit-report/audit-report.json') as f:
                      data = json.load(f)
                      print(len(data.get('vulnerabilities', [])))
              except:
                  print(0)
              PYTHON_EOF
            )
            echo "Dependencies (pip-audit): $([ "$DEPS" -eq 0 ] && echo 'âœ…' || echo 'âš ï¸')  $DEPS vulnerabilities"
          fi
          
          # Git secrets
          if [ -f coverage-artifacts/trufflehog-report/trufflehog-report.json ]; then
            SECRETS=$(python3 << 'PYTHON_EOF'
              import json
              try:
                  with open('coverage-artifacts/trufflehog-report/trufflehog-report.json') as f:
                      data = json.load(f)
                      print(len(data) if isinstance(data, list) else 0)
              except:
                  print(0)
              PYTHON_EOF
            )
            echo "Git History (TruffleHog): $([ "$SECRETS" -eq 0 ] && echo 'âœ…' || echo 'âš ï¸')  $SECRETS potential secrets"
          fi
          
          # Container vulnerabilities
          if [ -f coverage-artifacts/trivy-reports/trivy-report.json ]; then
            CONTAINER=$(python3 << 'PYTHON_EOF'
              import json
              try:
                  with open('coverage-artifacts/trivy-reports/trivy-report.json') as f:
                      data = json.load(f)
                      count = 0
                      for result in data.get('Results', []):
                          for vuln in result.get('Vulnerabilities', []):
                              if vuln.get('Severity') in ['CRITICAL', 'HIGH']:
                                  count += 1
                      print(count)
              except:
                  print(0)
              PYTHON_EOF
            )
            echo "Container Image (Trivy):  $([ "$CONTAINER" -eq 0 ] && echo 'âœ…' || echo 'âš ï¸')  $CONTAINER critical/high CVEs"
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
      
      - name: Check quality gates
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ¯ Quality Gates Status"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          if [ "${{ needs.test.result }}" = "success" ]; then
            echo "âœ… All tests passed"
            echo "âœ… Coverage requirements met"
            echo "âœ… Code quality verified"
            echo ""
            echo "Status: PASSED âœ…"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            exit 0
          else
            echo "âŒ Test failures detected"
            echo ""
            echo "Status: FAILED âŒ"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            exit 1
          fi

# ====== STAGE 7: REPORTS ======
  reports:
    name: Generate Reports
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: test
    if: "!contains(github.event.head_commit.message, '[deploy-only]')"
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download coverage artifacts
        uses: actions/download-artifact@v4
        with:
          path: coverage-artifacts
      
      - name: Generate HTML report index
        run: |
          cat > coverage-artifacts/index.html << 'EOF'
          <!DOCTYPE html>
          <html lang="en">
          <head>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <title>ğŸ“Š Test Coverage Reports</title>
              <style>
                  * { margin: 0; padding: 0; box-sizing: border-box; }
                  body {
                      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                      min-height: 100vh;
                      padding: 40px 20px;
                  }
                  .container { max-width: 1000px; margin: 0 auto; }
                  .header {
                      background: white;
                      padding: 40px;
                      border-radius: 10px;
                      box-shadow: 0 10px 30px rgba(0,0,0,0.2);
                      margin-bottom: 30px;
                      text-align: center;
                  }
                  .header h1 { color: #333; font-size: 2.5em; margin-bottom: 10px; }
                  .header p { color: #666; font-size: 1.1em; }
                  .reports-grid {
                      display: grid;
                      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                      gap: 20px;
                      margin-bottom: 30px;
                  }
                  .report-card {
                      background: white;
                      padding: 30px;
                      border-radius: 10px;
                      box-shadow: 0 5px 15px rgba(0,0,0,0.1);
                      transition: all 0.3s ease;
                      text-decoration: none;
                      color: inherit;
                      cursor: pointer;
                  }
                  .report-card:hover {
                      transform: translateY(-5px);
                      box-shadow: 0 15px 30px rgba(0,0,0,0.2);
                  }
                  .report-card h3 { color: #667eea; font-size: 1.3em; margin-bottom: 10px; }
                  .report-card p { color: #666; font-size: 0.9em; margin-bottom: 15px; }
                  .report-link {
                      display: inline-block;
                      background: #667eea;
                      color: white;
                      padding: 10px 20px;
                      border-radius: 5px;
                      text-decoration: none;
                      font-weight: 600;
                      transition: all 0.3s ease;
                  }
                  .report-link:hover { background: #764ba2; }
                  .status {
                      background: white;
                      padding: 30px;
                      border-radius: 10px;
                      box-shadow: 0 5px 15px rgba(0,0,0,0.1);
                  }
                  .status h2 { color: #333; margin-bottom: 20px; }
                  .status-item {
                      display: flex;
                      align-items: center;
                      padding: 15px;
                      background: #f5f5f5;
                      border-radius: 5px;
                      margin-bottom: 10px;
                  }
                  .status-icon { font-size: 1.5em; margin-right: 15px; }
              </style>
          </head>
          <body>
              <div class="container">
                  <div class="header">
                      <h1>ğŸ“Š Test Coverage Reports</h1>
                      <p>Coverage reports for different Python versions</p>
                  </div>
                  
                  <div class="reports-grid">
                      <a href="coverage-html-3.9/index.html" class="report-card">
                          <h3>ğŸ Python 3.9</h3>
                          <p>Detailed coverage report for Python 3.9 environment</p>
                          <span class="report-link">View Report â†’</span>
                      </a>
                      
                      <a href="coverage-html-3.10/index.html" class="report-card">
                          <h3>ğŸ Python 3.10</h3>
                          <p>Detailed coverage report for Python 3.10 environment</p>
                          <span class="report-link">View Report â†’</span>
                      </a>
                      
                      <a href="coverage-html-3.11/index.html" class="report-card">
                          <h3>ğŸ Python 3.11</h3>
                          <p>Detailed coverage report for Python 3.11 environment</p>
                          <span class="report-link">View Report â†’</span>
                      </a>
                      
                      <a href="coverage-html-3.12/index.html" class="report-card">
                          <h3>ğŸ Python 3.12</h3>
                          <p>Detailed coverage report for Python 3.12 environment</p>
                          <span class="report-link">View Report â†’</span>
                      </a>
                  </div>
                  
                  <div class="status">
                      <h2>ğŸ“ˆ Report Contents</h2>
                      <div class="status-item">
                          <span class="status-icon">ğŸ“Š</span>
                          <div><strong>Overall Coverage</strong> - Total code coverage percentage</div>
                      </div>
                      <div class="status-item">
                          <span class="status-icon">ğŸ“</span>
                          <div><strong>Coverage by File</strong> - Individual file metrics</div>
                      </div>
                      <div class="status-item">
                          <span class="status-icon">ğŸ“</span>
                          <div><strong>Line Coverage</strong> - Exact lines covered/missed</div>
                      </div>
                      <div class="status-item">
                          <span class="status-icon">ğŸ¯</span>
                          <div><strong>Gap Analysis</strong> - Areas needing more tests</div>
                      </div>
                  </div>
              </div>
          </body>
          </html>
          EOF
      
      - name: Upload all reports
        uses: actions/upload-artifact@v4
        with:
          name: all-coverage-reports
          path: coverage-artifacts/


  # ====== STAGE 8: NOTIFICATIONS ======
  notify:
    name: Pipeline Status
    runs-on: ubuntu-latest
    timeout-minutes: 5
    if: "!contains(github.event.head_commit.message, '[deploy-only]')"
    needs: [build, scan-image, lint, test, performance-test, quality-gates]
    
    steps:
      - name: Check pipeline status
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Pipeline Execution Summary"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "Build:            ${{ needs.build.result }}"
          echo "Image Scan:       ${{ needs.scan-image.result }}"
          echo "Lint:             ${{ needs.lint.result }}"
          echo "Tests:            ${{ needs.test.result }}"
          echo "Performance Test: ${{ needs.performance-test.result }}"
          echo "Quality Gates:    ${{ needs.quality-gates.result }}"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          if [ "${{ needs.build.result }}" = "success" ] && \
             [ "${{ needs.scan-image.result }}" = "success" ] && \
             [ "${{ needs.lint.result }}" = "success" ] && \
             [ "${{ needs.test.result }}" = "success" ] && \
             [ "${{ needs.performance-test.result }}" = "success" ] && \
             [ "${{ needs.quality-gates.result }}" = "success" ]; then
            echo ""
            echo "âœ… ALL CHECKS PASSED - READY FOR DEPLOYMENT"
            echo ""
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            exit 0
          else
            echo ""
            echo "âŒ PIPELINE FAILED - REVIEW LOGS ABOVE"
            echo ""
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            exit 1
          fi

# ====== ROLLING DEPLOYMENT STAGE ======
  deploy-prod:
    name: Deploy to Production (Rolling)
    runs-on: self-hosted
    environment: production
    timeout-minutes: 15
    needs: [build, scan-image, lint, test, performance-test, quality-gates, reports]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set environment variables
        run: |
          echo "IMAGE_NAME=$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV
          echo "DOCKER_IMAGE=ghcr.io/$(echo ${{ github.repository }} | tr '[:upper:]' '[:lower:]')" >> $GITHUB_ENV

      - name: Verify runner environment
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ–¥ï¸  Self-Hosted Runner Verification"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "Hostname: $(hostname)"
          echo "User:     $(whoami)"
          echo "Docker:   $(docker --version)"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

      # âœ… FIX: Proper secrets validation
      - name: Validate required secrets
        env:
          CONTAINER_NAME: ${{ secrets.CONTAINER_NAME }}
          CONTAINER_PORT_HOST: ${{ secrets.CONTAINER_PORT_HOST }}
        run: |
          EXIT_CODE=0
          
          if [ -z "$CONTAINER_NAME" ]; then
            echo "âŒ ERROR: CONTAINER_NAME secret is not set"
            EXIT_CODE=1
          fi
          
          if [ -z "$CONTAINER_PORT_HOST" ]; then
            echo "âŒ ERROR: CONTAINER_PORT_HOST secret is not set"
            EXIT_CODE=1
          fi
          
          if [ $EXIT_CODE -eq 1 ]; then
            echo ""
            echo "Please configure required secrets in repository settings:"
            echo "  - CONTAINER_NAME"
            echo "  - CONTAINER_PORT_HOST"
            exit 1
          fi
          
          echo "âœ… All required secrets are configured"

      # âœ… FIX: Proper image backup tagging
      - name: Create backup of current image
        env:
          CONTAINER_NAME: ${{ secrets.CONTAINER_NAME }}
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ’¾ Creating Backup of Current Deployment"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Check if current container exists
          if docker ps -a --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
            # Get the current image
            CURRENT_IMAGE=$(docker inspect --format='{{.Image}}' "$CONTAINER_NAME" 2>/dev/null || echo "")
            
            if [ -n "$CURRENT_IMAGE" ]; then
              # Create backup tag
              BACKUP_TAG="backup-$(date +%Y%m%d-%H%M%S)"
              docker tag "$CURRENT_IMAGE" "$DOCKER_IMAGE:$BACKUP_TAG"
              echo "âœ… Backup created: $DOCKER_IMAGE:$BACKUP_TAG"
              echo "BACKUP_IMAGE=$DOCKER_IMAGE:$BACKUP_TAG" >> $GITHUB_ENV
            else
              echo "âš ï¸  Could not determine current image"
            fi
          else
            echo "â„¹ï¸  No existing container to backup (first deployment)"
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

      # âœ… ROLLING DEPLOYMENT: Start new container before stopping old
      - name: Rolling deployment
        env:
          CONTAINER_NAME: ${{ secrets.CONTAINER_NAME }}
          CONTAINER_PORT: ${{ secrets.CONTAINER_PORT_HOST }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸš€ Starting Rolling Deployment"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          IMAGE_TAG="latest"
          NEW_CONTAINER="${CONTAINER_NAME}-new"
          OLD_CONTAINER="${CONTAINER_NAME}"
          NEW_PORT=$((CONTAINER_PORT + 1000))
          
          echo "Configuration:"
          echo "  ğŸ“¦ Image:         $DOCKER_IMAGE:$IMAGE_TAG"
          echo "  ğŸ·ï¸  New Container: $NEW_CONTAINER"
          echo "  ğŸ”Œ New Port:      $NEW_PORT:5000"
          echo "  ğŸ·ï¸  Old Container: $OLD_CONTAINER"
          echo "  ğŸ”Œ Old Port:      $CONTAINER_PORT:5000"
          echo ""
          
          # Login to registry
          echo "ğŸ” Authenticating to GitHub Container Registry..."
          echo "$GITHUB_TOKEN" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
          
          if [ $? -ne 0 ]; then
            echo "âŒ ERROR: Registry authentication failed"
            exit 1
          fi
          echo "âœ… Authentication successful"
          echo ""
          
          # Pull new image
          echo "ğŸ“¥ Pulling new Docker image..."
          docker pull "$DOCKER_IMAGE:$IMAGE_TAG"
          
          if [ $? -ne 0 ]; then
            echo "âŒ ERROR: Failed to pull image"
            exit 1
          fi
          echo "âœ… Image pulled successfully"
          echo ""
          
          # Start new container on different port
          echo "ğŸš€ Starting new container..."
          docker run -d \
            --memory="512m" \
            --cpus="1.0" \
            --name "$NEW_CONTAINER" \
            -p "$NEW_PORT:5000" \
            -e FLASK_ENV=production \
            -e FLASK_DEBUG=False \
            --restart unless-stopped \
            "$DOCKER_IMAGE:$IMAGE_TAG"
          
          if [ $? -ne 0 ]; then
            echo "âŒ ERROR: Failed to start new container"
            exit 1
          fi
          echo "âœ… New container started on port $NEW_PORT"
          echo ""
          
          # Health check new container
          echo "ğŸ¥ Performing health check on new container..."
          HEALTH_SUCCESS=0
          
          for i in {1..10}; do
            sleep 5
            if curl -sf "http://localhost:$NEW_PORT/api/health" --max-time 5 >/dev/null 2>&1; then
              HEALTH_SUCCESS=1
              echo "âœ… Health check passed (attempt $i)"
              break
            else
              echo "â³ Health check attempt $i/10..."
            fi
          done
          
          if [ $HEALTH_SUCCESS -eq 0 ]; then
            echo ""
            echo "âŒ ERROR: New container failed health check"
            echo "ğŸ“‹ Container logs:"
            docker logs "$NEW_CONTAINER" --tail=50
            echo ""
            echo "ğŸ”„ Rolling back..."
            docker stop "$NEW_CONTAINER" 2>&1 || true
            docker rm "$NEW_CONTAINER" 2>&1 || true
            exit 1
          fi
          
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ”„ Switching Traffic to New Container"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Stop old container (if exists)
          if docker ps --format '{{.Names}}' | grep -q "^${OLD_CONTAINER}$"; then
            echo "ğŸ›‘ Stopping old container..."
            docker stop "$OLD_CONTAINER" --time 30 2>&1 || true
            echo "âœ… Old container stopped gracefully"
          else
            echo "â„¹ï¸  No old container to stop (first deployment)"
          fi
          
          # Remove old container
          if docker ps -a --format '{{.Names}}' | grep -q "^${OLD_CONTAINER}$"; then
            echo "ğŸ—‘ï¸  Removing old container..."
            docker rm "$OLD_CONTAINER" 2>&1 || true
            echo "âœ… Old container removed"
          fi
          
          # Update port mapping by recreating with correct port
          echo "ğŸ”„ Recreating container with production port..."
          docker stop "$NEW_CONTAINER" --time 5 2>&1 || true
          
          # Get the image from the new container
          NEW_IMAGE=$(docker inspect --format='{{.Image}}' "$NEW_CONTAINER" 2>/dev/null)
          
          docker rm "$NEW_CONTAINER" 2>&1 || true
          
          # Start final container with correct name and port
          docker run -d \
            --memory="512m" \
            --cpus="1.0" \
            --name "$CONTAINER_NAME" \
            -p "$CONTAINER_PORT:5000" \
            -e FLASK_ENV=production \
            -e FLASK_DEBUG=False \
            --restart unless-stopped \
            "$DOCKER_IMAGE:$IMAGE_TAG"
          
          echo "âœ… Container recreated with production configuration"
          echo ""
          
          # Final health check
          echo "ğŸ¥ Performing final health check..."
          sleep 5
          
          FINAL_HEALTH=0
          for i in {1..5}; do
            if curl -sf "http://localhost:$CONTAINER_PORT/api/health" --max-time 5 >/dev/null 2>&1; then
              FINAL_HEALTH=1
              echo "âœ… Final health check passed"
              break
            fi
            sleep 3
          done
          
          if [ $FINAL_HEALTH -eq 0 ]; then
            echo "âŒ ERROR: Final health check failed"
            echo ""
            echo "ğŸ”„ Attempting rollback to backup..."
            
            docker stop "$CONTAINER_NAME" 2>&1 || true
            docker rm "$CONTAINER_NAME" 2>&1 || true
            
            if [ -n "$BACKUP_IMAGE" ]; then
              docker run -d \
                --memory="512m" \
                --cpus="1.0" \
                --name "$CONTAINER_NAME" \
                -p "$CONTAINER_PORT:5000" \
                -e FLASK_ENV=production \
                -e FLASK_DEBUG=False \
                --restart unless-stopped \
                "$BACKUP_IMAGE"
              echo "âš ï¸  Rolled back to backup: $BACKUP_IMAGE"
            fi
            exit 1
          fi
          
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "âœ… ROLLING DEPLOYMENT SUCCESSFUL"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸŒ Application: http://localhost:$CONTAINER_PORT"
          echo "ğŸ¥ Health:      http://localhost:$CONTAINER_PORT/api/health"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

      - name: Record deployment metrics
        if: success()
        env:
          DEPLOYMENT_TIMESTAMP: ${{ github.event.head_commit.timestamp }}
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Recording Deployment Metrics"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Calculate deployment duration
          DEPLOY_START=$(date +%s)
          DEPLOY_END=$(date +%s)
          DURATION=$((DEPLOY_END - DEPLOY_START))
          
          # Prepare metrics payload
          METRICS_PAYLOAD=$(cat <<EOF
          {
            "deployment_id": "${{ github.run_id }}",
            "repository": "${{ github.repository }}",
            "branch": "${{ github.ref_name }}",
            "commit_sha": "${{ github.sha }}",
            "commit_message": "${{ github.event.head_commit.message }}",
            "deployer": "${{ github.actor }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "duration_seconds": $DURATION,
            "status": "success",
            "environment": "production",
            "deployment_type": "rolling",
            "image_tag": "latest",
            "image_digest": "${{ needs.build.outputs.image-digest }}"
          }
          EOF
          )
          
          echo "Metrics to record:"
          echo "$METRICS_PAYLOAD" | jq '.' 2>/dev/null || echo "$METRICS_PAYLOAD"
          
          # Send to metrics endpoint (if configured)
          if [ -n "${{ secrets.METRICS_ENDPOINT }}" ]; then
            curl -X POST "${{ secrets.METRICS_ENDPOINT }}" \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer ${{ secrets.METRICS_API_KEY }}" \
              -d "$METRICS_PAYLOAD" || echo "âš ï¸ Failed to send metrics"
          else
            echo "â„¹ï¸  No metrics endpoint configured (METRICS_ENDPOINT secret not set)"
          fi
          
          # Log to GitHub Actions summary
          echo "### ğŸ“Š Deployment Metrics" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Deployment ID | ${{ github.run_id }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Commit | \`${{ github.sha }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Branch | ${{ github.ref_name }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Deployer | @${{ github.actor }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Deployment Type | ğŸ”„ Rolling |" >> $GITHUB_STEP_SUMMARY
          echo "| Duration | ${DURATION}s |" >> $GITHUB_STEP_SUMMARY
          echo "| Status | âœ… Success |" >> $GITHUB_STEP_SUMMARY
          echo "| Timestamp | $(date -u +%Y-%m-%dT%H:%M:%SZ) |" >> $GITHUB_STEP_SUMMARY
          
          echo "âœ… Deployment metrics recorded"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        continue-on-error: true

      - name: Verify deployment
        env:
          CONTAINER_NAME: ${{ secrets.CONTAINER_NAME }}
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š Deployment Verification"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          if docker ps | grep -q "$CONTAINER_NAME"; then
            echo "âœ… Container Status: Running"
            echo ""
            docker ps --filter "name=$CONTAINER_NAME" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
            echo ""
            echo "ğŸ“‹ Recent logs:"
            docker logs "$CONTAINER_NAME" --tail=10
          else
            echo "âŒ Container not running"
            exit 1
          fi
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

      - name: Run smoke tests
        env:
          CONTAINER_NAME: ${{ secrets.CONTAINER_NAME }}
          CONTAINER_PORT: ${{ secrets.CONTAINER_PORT_HOST }}
        run: |
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ§ª Running Post-Deployment Smoke Tests"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          BASE_URL="http://localhost:$CONTAINER_PORT"
          FAILED_TESTS=0
          TOTAL_TESTS=0
          
          # Function to run a smoke test
          run_smoke_test() {
            local test_name="$1"
            local endpoint="$2"
            local expected_status="${3:-200}"
            
            TOTAL_TESTS=$((TOTAL_TESTS + 1))
            echo ""
            echo "Test $TOTAL_TESTS: $test_name"
            echo "  Endpoint: $endpoint"
            
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "$BASE_URL$endpoint" --max-time 10)
            
            if [ "$HTTP_CODE" = "$expected_status" ]; then
              echo "  âœ… PASSED (HTTP $HTTP_CODE)"
            else
              echo "  âŒ FAILED (Expected HTTP $expected_status, got HTTP $HTTP_CODE)"
              FAILED_TESTS=$((FAILED_TESTS + 1))
            fi
          }
          
          # Critical smoke tests
          run_smoke_test "Health Check" "/api/health" "200"
          run_smoke_test "Root Endpoint" "/" "200"
          
          # Response time test
          echo ""
          echo "Test: Response Time"
          RESPONSE_TIME=$(curl -o /dev/null -s -w '%{time_total}' "$BASE_URL/api/health")
          RESPONSE_TIME_MS=$(echo "$RESPONSE_TIME * 1000" | bc)
          echo "  Response time: ${RESPONSE_TIME_MS}ms"
          
          if [ $(echo "$RESPONSE_TIME < 1.0" | bc) -eq 1 ]; then
            echo "  âœ… PASSED (< 1000ms)"
          else
            echo "  âš ï¸  WARNING (> 1000ms)"
          fi
          
          # Container health test
          echo ""
          echo "Test: Container Health"
          RUNNING=$(docker inspect -f '{{.State.Running}}' "$CONTAINER_NAME" 2>/dev/null || echo "false")
          if [ "$RUNNING" = "true" ]; then
            echo "  âœ… PASSED (Container is running)"
          else
            echo "  âŒ FAILED (Container is not running)"
            FAILED_TESTS=$((FAILED_TESTS + 1))
          fi
          
          # Memory usage test
          echo ""
          echo "Test: Memory Usage"
          MEMORY_USAGE=$(docker stats --no-stream --format "{{.MemPerc}}" "$CONTAINER_NAME" | sed 's/%//')
          echo "  Memory usage: ${MEMORY_USAGE}%"
          
          if [ $(echo "$MEMORY_USAGE < 80.0" | bc -l) -eq 1 ]; then
            echo "  âœ… PASSED (< 80%)"
          else
            echo "  âš ï¸  WARNING (> 80%)"
          fi
          
          # Results summary
          echo ""
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“‹ Smoke Test Results"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "Total Tests:  $TOTAL_TESTS"
          echo "Passed:       $((TOTAL_TESTS - FAILED_TESTS))"
          echo "Failed:       $FAILED_TESTS"
          echo ""
          
          if [ $FAILED_TESTS -eq 0 ]; then
            echo "âœ… ALL SMOKE TESTS PASSED"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            
            echo "### ğŸ§ª Smoke Tests: âœ… PASSED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All $TOTAL_TESTS smoke tests passed successfully." >> $GITHUB_STEP_SUMMARY
            
            exit 0
          else
            echo "âŒ SMOKE TESTS FAILED"
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            
            echo "### ğŸ§ª Smoke Tests: âŒ FAILED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "$FAILED_TESTS out of $TOTAL_TESTS tests failed." >> $GITHUB_STEP_SUMMARY
            
            echo ""
            echo "ğŸ”„ INITIATING ROLLBACK DUE TO FAILED SMOKE TESTS"
            
            # Rollback to backup
            docker stop "$CONTAINER_NAME" 2>&1 || true
            docker rm "$CONTAINER_NAME" 2>&1 || true
            
            if [ -n "$BACKUP_IMAGE" ]; then
              docker run -d \
                --memory="512m" \
                --cpus="1.0" \
                --name "$CONTAINER_NAME" \
                -p "$CONTAINER_PORT:5000" \
                -e FLASK_ENV=production \
                -e FLASK_DEBUG=False \
                --restart unless-stopped \
                "$BACKUP_IMAGE"
              echo "âš ï¸  Rolled back to backup due to smoke test failures"
            fi
            exit 1
          fi

      - name: Cleanup old images
        if: success()
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ§¹ Cleaning Up Old Images"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Keep only the last 5 backup images
          docker images "$DOCKER_IMAGE" --format "{{.Tag}}" | \
            grep "^backup-" | \
            sort -r | \
            tail -n +6 | \
            xargs -r -I {} docker rmi "$DOCKER_IMAGE:{}" 2>/dev/null || true
          
          # Remove dangling images
          docker image prune -f
          
          echo "âœ… Cleanup completed"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        continue-on-error: true

      - name: Cleanup
        if: always()
        run: |
          docker logout ghcr.io 2>/dev/null || true
          [ -d ~/.ssh ] && rm -rf ~/.ssh || true



# âœ… IMPROVEMENT: Better concurrency control
concurrency:
  group: deploy-${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' && github.ref != 'refs/heads/develop' }}
